import streamlit as st
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
from PIL import Image, ImageDraw
import io
import os

# --- 专转 ---
#  爪专 -OpenAI 专住  ( 拽)

# --- 注爪 ---
st.set_page_config(layout="wide", page_title="Sunrise Mobile")
st.markdown("""
    <style>
    .stApp { background-color: #e0f7fa; }
    h1, h2, h3, p, label { color: black !important; }
    
    /* 驻转专 拽    */
    .stButton button { 
        background-color: #ffcc80 !important; 
        color: black !important; 
        border: 2px solid black !important;
        font-weight: bold;
        width: 100%;
        height: 60px;
        font-size: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# --- 拽 拽转 ( ) ---
def analyze_text(text):
    res = {"parts": [], "pain": 0}
    t = text
    
    #  爪
    side = "砖" if "砖" in t else ""
    view = "专" if any(w in t for w in ["", "专", "注专祝"]) else "拽"
    
    # 驻 专
    if "转祝" in t: res["parts"].append(f"转祝 {side} - {view}")
    elif "专" in t: res["parts"].append(f"专 {side} - {view}")
    elif "专砖" in t: res["parts"].append(f"专砖 - {view}")
    elif " 转转" in t: res["parts"] = [" 转转"]
    elif "" in t: res["parts"] = [" 注"]
    
    #   (住驻专)
    for w in t.split():
        if w.isdigit(): res["pain"] = int(w)
        
    return res

# --- 爪专 驻 ---
def draw_body_map(parts):
    # 住 注转 转
    img_path = "body_male.png" 
    if not os.path.exists(img_path): return None
    
    img = Image.open(img_path).convert("RGBA")
    overlay = Image.new('RGBA', img.size, (255,255,255,0))
    draw = ImageDraw.Draw(overlay)
    
    # 拽专转 住住转 (转 专)
    coords = {
        "转祝  - 拽": (95, 120), "转祝 砖 - 拽": (205, 120),
        "专  - 拽": (115, 460), "专 砖 - 拽": (185, 460),
        "专砖 - 拽": (150, 40), " 转转": (450, 240)
    }
    
    for part in parts:
        if part in coords:
            x, y = coords[part]
            # 注  
            draw.ellipse((x-25, y-25, x+25, y+25), fill=(255, 0, 0, 150))
    
    return Image.alpha_composite(img, overlay)

# --- 砖拽 驻拽爪 ---
c1, c2 = st.columns([1, 5])
with c1: st.write("## ")
with c2: st.title("Sunrise Mobile")

if 'transcription' not in st.session_state: st.session_state.transcription = ""

# --- 驻转专 拽 砖 (砖注 驻) ---
st.info(" 抓 拽 (驻注 转 转, 驻注 转 住)")

# 专  祝 转 sr.Microphone() 注转
audio = mic_recorder(
    start_prompt=" 转 拽",
    stop_prompt="癸 住 砖专",
    key='recorder',
    format="wav"
)

if audio:
    # 注 拽 专拽 专 砖住转
    st.toast("注 砖注...")
    r = sr.Recognizer()
    try:
        audio_data = io.BytesIO(audio['bytes'])
        with sr.AudioFile(audio_data) as source:
            audio_content = r.record(source)
            text = r.recognize_google(audio_content, language="he-IL")
            st.session_state.transcription = text
    except Exception as e:
        st.error(" 爪转  转 专")

# --- 转爪转 转爪转 ---
st.markdown("---")

# 转 拽住
analysis = analyze_text(st.session_state.transcription)

col_form, col_map = st.columns(2)

with col_form:
    st.subheader("驻专")
    st.text_area("转", value=st.session_state.transcription, height=100)
    st.slider("注爪转 ", 0, 10, value=analysis['pain'])

with col_map:
    st.subheader("驻")
    if analysis['parts']:
        st.success(f": {', '.join(analysis['parts'])}")
        
    final_img = draw_body_map(analysis['parts'])
    if final_img:
        st.image(final_img, use_container_width=True)
    else:
        st.warning(" 爪 转转 祝 (body_male.png)")